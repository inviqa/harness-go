attributes.default:
  app:
    binary: app
    src_path: .
    module_path: = @('app.src_path')
    health_port: 80
    services: []
    default_port:
      name: http
      port: 80
    ingress:
      # possible ingress types are standard, istio, or ~ for none
      # note istio requires a cluster that has istio configured as the ingress controller
      type: standard
      protocol: = @('app.default_port.protocol')
    bundle_certs: no
    packages: []

  domain: my127.site
  hostname: = @('namespace') ~ '.' ~ @('domain')

  database:
    # possible platforms are mysql, postgres or ~ for none
    platform: postgres
    host: postgres
    user: app
    pass: app
    name: app
    root_pass: DV6RdNY3QcFsBk7V

  docker:
    config: null # deprecated
    # If using gitops helm chart repositories, it's recommended to put this configuration
    # in the values.yml in there now instead of project application repositories
    image_pull_config: = @('docker.config')
    registry:
      url: = get_docker_registry(@('docker.repository'))
      username: = @('docker.username') # for backwards compatibility
      password: = @('docker.password') # for backwards compatibility
    repository: = @("workspace.name")
    tagPrefix: = ''

  git:
    config_global:
      - key: 'url.${GITHUB_TOKEN}:x-oauth-basic@github.com/.insteadOf'
        value: https://github.com/
        when: = @('github.token') != null
        buildArgs: 
          GITHUB_TOKEN: = @('github.token')
      - key: 'url.ssh://git@github.com/.insteadOf'
        value: https://github.com/
        when: = @('github.ssh_deploy_key') != null
        buildArgs:
          SSH_PRIVATE_KEY: = @('github.ssh_deploy_key')

  go:
    version: 1.15
    environment:
      CGO_ENABLED: '0'
      GOPRIVATE: github.com/inviqa/*
    modules:
      after:
        steps: []
      before:
        steps: []
    formatter: gofmt
    gocyclo:
      threshold: 10

  helm:
    additional_schema_locations: https://inviqa.github.io/kubernetes-json-schema/schema
    feature:
      # Note: be very careful considering disabling this, as in most cases
      # it causes the secrets in it to be stored plaintext on filesystem
      # or in helm chart repositories
      # requires sealed-secrets k8s operator
      sealed_secrets: true
    timeout: 300

    sealed_secrets:
      # location of the sealed-secret service to download the active certificate from
      controller_name: sealed-secrets
      controller_namespace: sealed-secrets
      # Use local file (or fetch from http url) as the certificate
      # If null, it will be fetched from the controller in the current kubectl context
      certificate_file: ~
      # A namespace the secret should be only decryptable by
      # Ignored if scope is cluster-wide.
      # If null, it will be fetched from the current kubectl context
      namespace: ~
      # The scope under which a secret can be decrypted
      # Either cluster-wide, namespace-wide, or strict
      scope: "= @('helm.sealed_secrets.namespace') ? 'namespace-wide' : 'cluster-wide'"
  
  jenkins:
    credentials:
      my127ws_key: = @('workspace.name') ~ '-my127ws-key'

  # these settings are only relevant when the respective service is enabled in
  # app.services
  persistence:
    mysql:
      enabled: true
      accessMode: ReadWriteOnce
      size: 4Gi
    postgres:
      enabled: true
      accessMode: ReadWriteOnce
      size: 4Gi

  pipeline:
    publish:
      enabled: no
    preview:
      enabled: no
      namespace: = @('workspace.name') ~ '-' ~ slugify(branch())
      hostname:  = @('pipeline.preview.namespace') ~ '.example.com'
    base:
      resourcePrefix: ~
      hostname: = @('pipeline.base.namespace') ~ '.example.com'
    qa:
      enabled: no
      namespace: = @('workspace.name') 
      hostname: = @('pipeline.qa.namespace') ~ '.' ~ @('domain')
      resourcePrefix: ~

  resources:
    requests:
      memory:
        mysql: "512Mi"
        postgres: "512Mi"
    limits:
      memory:
        mysql: "512Mi"
        postgres: "512Mi"
